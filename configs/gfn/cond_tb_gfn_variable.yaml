_target_: chunkgfn.gfn.cond_tb_gfn_variable.Cond_TBGFN_Variable

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  weight_decay: 0.0

scheduler: null

forward_model:
  _target_: chunkgfn.models.rnn.RNN
  num_layers: 1
  hidden_dim: 128
  input_vocab_size: 4
  state_vocab_size: 4
  act:
    _target_: torch.nn.ReLU

partition_model:
  _target_: chunkgfn.models.rnn.logZ
  num_layers: 1
  hidden_dim: 128
  input_vocab_size: 4
  act:
    _target_: torch.nn.ReLU

criterion:
  _target_: chunkgfn.rewards.mse.MSE

epsilon_scheduler:
  _target_: chunkgfn.schedulers.linear_schedule.LinearSchedule
  initial_value: 1
  final_value: 0
  max_epochs: ${trainer.max_epochs}

replay_buffer:
  _target_: chunkgfn.replay_buffer.random_replay.RandomReplay
  capacity: 10000

lr: 3e-4
partition_lr: 3e-4
monitor: train/loss
n_samples: 1000 # Number of samples for the tokenizer