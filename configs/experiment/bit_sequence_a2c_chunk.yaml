# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /environment: bit_sequence.yaml
  - override /algo: a2c.yaml
  - override /trainer: default.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

seed: 42

environment:
  output_padding_mask: True

trainer:
  max_epochs: 250
  check_val_every_n_epoch: 10

algo:
  forward_policy:
    _target_: chunkgfn.models.transformer.Transformer
    num_layers: 4
    hidden_dim: 128
    state_dim: 3
    max_len: ${environment.max_len}
    num_head: 8
    output_dim: ${algo.action_embedder.action_embedding_dimension}
    use_bos_token: True
  
  critic:
    _target_: chunkgfn.models.transformer.Transformer
    num_layers: 4
    hidden_dim: 128
    state_dim: 3
    max_len: ${environment.max_len}
    num_head: 8
    output_dim: 1
    use_bos_token: True
  
  action_embedder:
    _target_: chunkgfn.models.action_encoder.ActionEncoder
    n_primitive_actions: 3
    num_layers: 4
    hidden_dim: 128
    max_len: ${environment.max_len}
    num_head: 8
  
  chunk_algorithm: bpe
  chunk_type: basic
  n_chunks: 1
  library_update_frequency: 10
  n_samples: 10000

logger:
  wandb:
    group: "bit_sequence"