# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: bit_sequence.yaml
  - override /gfn: tb_gfn_prioritized.yaml
  - override /trainer: default.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

seed: 42

data:
  max_len: 32
  num_modes: 60
  num_train_iterations: 100
  oracle_difficulty: medium
  sample_exact_length: True # Whether to always sample sequences of length `max_len` or not
  threshold: 0.9
  batch_size: 64

trainer:
  max_epochs: 1000

gfn:
  forward_model:
    _target_: chunkgfn.models.rnn.UnconditionalRNN
    num_layers: 1
    hidden_dim: 128
    state_dim: 3
    n_actions: 3
    act:
      _target_: torch.nn.ReLU
  
  replay_buffer:
    cutoff_distance: 3
  reward_temperature: 0.3333

logger:
  wandb:
    group: "bit_sequence"