{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "from chunkgfn.datamodules.selfies_sequence import SELFIESSequenceModule\n",
    "from chunkgfn.gfn.tb_gfn import TBGFN\n",
    "from chunkgfn.gfn.tb_gfn_variable import TBGFN_Variable\n",
    "from chunkgfn.gfn.tb_gfn_chunk_replacement import TBGFN_Chunk_Replacement\n",
    "\n",
    "from torch.distributions import Categorical\n",
    "from scipy.stats import linregress, spearmanr\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from tqdm.notebook import tqdm\n",
    "from einops import repeat, rearrange\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from polyleven import levenshtein\n",
    "\n",
    "from wandb.proto import wandb_internal_pb2\n",
    "from wandb.sdk.internal import datastore\n",
    "import selfies as sf\n",
    "import rdkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(jobid, seed, gfn_approach, n_samples=2**10):\n",
    "    dm = SELFIESSequenceModule.load_from_checkpoint(f\"/network/scratch/o/oussama.boussif/chunkgfn/logs/selfies/runs/{jobid}/checkpoints/last.ckpt\")\n",
    "    if gfn_approach == \"chunk_normal\":\n",
    "        gfn = TBGFN_Variable.load_from_checkpoint(f\"/network/scratch/o/oussama.boussif/chunkgfn/logs/selfies/runs/{jobid}/checkpoints/last.ckpt\")\n",
    "    elif gfn_approach == \"chunk_replacement\":\n",
    "        gfn = TBGFN_Chunk_Replacement.load_from_checkpoint(f\"/network/scratch/o/oussama.boussif/chunkgfn/logs/selfies/runs/{jobid}/checkpoints/last.ckpt\")\n",
    "    elif gfn_approach == \"no_chunk\":\n",
    "        gfn = TBGFN.load_from_checkpoint(f\"/network/scratch/o/oussama.boussif/chunkgfn/logs/selfies/runs/{jobid}/checkpoints/last.ckpt\")\n",
    "    dm.action_frequency = torch.zeros(len(dm.actions))\n",
    "    batch_size = n_samples\n",
    "\n",
    "    L.seed_everything(seed)\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        s0 = dm.s0.to(gfn.device)\n",
    "        state = repeat(s0, \" ... -> b ...\", b=batch_size)\n",
    "        bs = state.shape[0]\n",
    "\n",
    "        # Start unrolling the trajectories\n",
    "        actions = []\n",
    "        trajectories = []\n",
    "        dones = []\n",
    "        done = torch.zeros((bs)).to(state).bool()\n",
    "        trajectory_length = (\n",
    "            torch.zeros((bs)).to(state).long()\n",
    "        )  # This tracks the length of trajetcory for each sample in the batch\n",
    "\n",
    "        while not done.all():\n",
    "            action_indices = dm.action_indices\n",
    "            library_embeddings = []\n",
    "            for action, indices in action_indices.items():\n",
    "                library_embeddings.append(\n",
    "                    gfn.action_model(\n",
    "                        torch.LongTensor(indices).to(gfn.device).unsqueeze(0)\n",
    "                    )\n",
    "                )\n",
    "            library_embeddings = torch.cat(library_embeddings, dim=0)\n",
    "            action_embedding = gfn.forward_model(\n",
    "                dm.preprocess_states(state)\n",
    "            )\n",
    "            dim = action_embedding.shape[-1]\n",
    "            p_f_s = torch.einsum(\"bd, nd -> bn\", action_embedding, library_embeddings) / (\n",
    "                dim**0.5\n",
    "            )  # Same as in softmax\n",
    "\n",
    "            uniform_dist_probs = torch.ones_like(p_f_s).to(p_f_s)\n",
    "\n",
    "            valid_actions_mask = dm.get_forward_mask(state)\n",
    "\n",
    "            p_f_s = torch.where(\n",
    "                valid_actions_mask,\n",
    "                p_f_s,\n",
    "                torch.tensor(-1e6).to(p_f_s),\n",
    "            )\n",
    "            uniform_dist_probs = torch.where(\n",
    "                valid_actions_mask,\n",
    "                uniform_dist_probs,\n",
    "                torch.tensor(0.0).to(uniform_dist_probs),\n",
    "            )\n",
    "\n",
    "            cat = Categorical(logits=p_f_s)\n",
    "\n",
    "            act = cat.sample()\n",
    "\n",
    "            new_state, done = dm.forward_step(state, act)\n",
    "            trajectory_length += ~done  # Increment the length of the trajectory for each sample in the batch as long it's not done.\n",
    "\n",
    "            actions.append(act)\n",
    "            trajectories.append(state)\n",
    "            dones.append(done.clone())\n",
    "\n",
    "            state = new_state.clone()\n",
    "\n",
    "\n",
    "        logreward = dm.compute_logreward(state).to(\n",
    "                state.device\n",
    "        )\n",
    "        trajectories.append(state)\n",
    "        dones.append(torch.ones((bs)).to(state).bool())\n",
    "        trajectories = torch.stack(trajectories, dim=1)\n",
    "        actions = torch.stack(actions, dim=1)\n",
    "        dones = torch.stack(dones, dim=1)\n",
    "    return logreward, state, actions, trajectories, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_strings(states: torch.Tensor) -> list[str]:\n",
    "    \"\"\"Convert the states to raw data.\n",
    "    Args:\n",
    "        states (torch.Tensor[batch_size, max_len, dim]): Batch of states.\n",
    "    Returns:\n",
    "        raw (list[str]): List of states in their string representation.\n",
    "    \"\"\"\n",
    "    atomic_tokens = [\"A\", \"C\", \"G\", \"U\"]\n",
    "    padding_token = -torch.ones(len(atomic_tokens))\n",
    "    strings = []\n",
    "    for state in states.cpu():\n",
    "        # Cut the state before it arrives at [-1,-1,...]\n",
    "        nonzero = (state == padding_token).nonzero()\n",
    "        if len(nonzero) > 0:\n",
    "            state = state[: nonzero[0][0]]\n",
    "\n",
    "        indices = state.argmax(dim=-1)\n",
    "        strings.append(\"\".join([atomic_tokens[i] for i in indices]))\n",
    "    return strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6092, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6105, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6111, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "logreward, state, actions, trajectories, dones = get_samples(4703138, 2024, \"chunk_normal\", n_samples=2**14)\n",
    "print(torch.topk(logreward, k=100).values.exp().median())\n",
    "logreward, state, actions, trajectories, dones = get_samples(4703129, 1998, \"chunk_normal\", n_samples=2**14)\n",
    "print(torch.topk(logreward, k=100).values.exp().median())\n",
    "logreward, state, actions, trajectories, dones = get_samples(4703147, 42, \"chunk_normal\", n_samples=2**14)\n",
    "print(torch.topk(logreward, k=100).values.exp().median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = SELFIESSequenceModule.load_from_checkpoint(f\"/network/scratch/o/oussama.boussif/chunkgfn/logs/selfies/runs/{4703147}/checkpoints/last.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies_strings = [sf.decoder(dm._string_to_selfie(s.replace(\"<EOS>\", \"\"))) for s in dm.to_strings(state[torch.topk(logreward, k=100).indices])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BrS[C@H1]/C=N[C@@H1][C@H1]Br', 0.7058209190176709),\n",
       " ('Br[C@H1]P(O)SP', 0.6991817040419113),\n",
       " ('Br[C@@H1]/CS(Br)[C@H1]', 0.6956880832428124),\n",
       " ('BrO[C@@H1]OBr', 0.6829070479362431),\n",
       " ('BrOC[N+1]C=CBr', 0.6768116944275369),\n",
       " ('BrC[C@@H1](O)[N+1]Br', 0.6766100579045485),\n",
       " ('[NH1+1][C@@H1]=C(SBr)SF', 0.6740504678815359),\n",
       " ('[NH1+1]/CCS(Br)Br', 0.6716175674409508),\n",
       " ('BrN[C@@H1][C@@H1]Br', 0.6685518401149211),\n",
       " ('BrP[C@H1]SBr', 0.6643524697412498),\n",
       " ('Br[N+1][C@@H1]OBr', 0.6634426989084399),\n",
       " ('Br[C@@H1][NH1+1][C@@H1]=C(Br)[NH1]', 0.6610619953065637),\n",
       " ('Br[C@@H1]=C[C@@H1][C@H1]Br', 0.6592862236472985),\n",
       " ('Br[C@H1]P=NPN', 0.6582621068702441),\n",
       " ('N(P)PPBr', 0.6578608758938106),\n",
       " ('[NH1]P(Br)NC=CF', 0.6564924778698977),\n",
       " ('O[C@H1][C@@H1]SBr', 0.6545925023295471),\n",
       " ('BrOP[N+1]Br', 0.6520067433183583),\n",
       " ('[C@@H1](N)[C@@H1]SBr', 0.648360595706495),\n",
       " ('N[C@H1]S[C@@H1]Br', 0.648360595706495),\n",
       " ('N[C@@H1]/CSBr', 0.6467286435545225),\n",
       " ('CN[C@H1]SBr', 0.6457259053871923),\n",
       " ('O/C/CSBr', 0.645225145416994),\n",
       " ('BrCCSBr', 0.6435396962132625),\n",
       " ('C/C/C[C@H1]=CSBr', 0.6428535686188426),\n",
       " ('NCPSBr', 0.6421429861664539),\n",
       " ('ClP(Br)=CPBr', 0.6416386412207461),\n",
       " ('Br[N+1]C[C@H1]Br', 0.6413183117428695),\n",
       " ('O1[C@@H1]=NP1[C@@H1]Br', 0.6387330266445521),\n",
       " ('Br[NH1]/C=CBr', 0.6367055506415303),\n",
       " ('[N+1]C([C@H1])PS[C@@H1]Br', 0.633328452559336),\n",
       " ('S(Br)[C@@H1]Br', 0.6331079014322919),\n",
       " ('Cl[C@@H1]=CP(Br)N', 0.6282019349706922),\n",
       " ('N[C@@H1]P=COBr', 0.6276139628401237),\n",
       " ('Br[NH2+1]C[C@H1]Br', 0.6257302159286804),\n",
       " ('[NH1]1PP1O/C[C@@H1]', 0.6236556879397782),\n",
       " ('Br[C@H1]=C[C@H1]CN', 0.623515197436077),\n",
       " ('[C@H1]CSC[C@@H1]COBr', 0.6213394084947327),\n",
       " ('P=CP(=C)SBr', 0.6208792896200104),\n",
       " ('Br[C@@H1]CSCl', 0.6196101828319448),\n",
       " ('BrOC[C@@H1]=CCl', 0.6179549648684722),\n",
       " ('Cl[N+1]C[C@H1]SBr', 0.6176766688981336),\n",
       " ('N[C@@H1][C@H1]S(=C)Br', 0.6172047564850235),\n",
       " ('O[C@H1]SOBr', 0.6163691512897689),\n",
       " ('P[N+1]/C[C@@H1]=CPBr', 0.6157257758623205),\n",
       " ('ClOPPBr', 0.6155009879149388),\n",
       " ('BrP(C)[NH1][C@H1]O', 0.6150793413030251),\n",
       " ('[NH1]PPSBr', 0.6143520502766853),\n",
       " ('[NH2+1][C@H1]SPBr', 0.6126560257635729),\n",
       " ('BrONOCl', 0.6121654183317593),\n",
       " ('Br[C@@H1]S/CS=NBr', 0.6110800696407468),\n",
       " ('BrO[C@@H1]Br', 0.6105376387647071),\n",
       " ('PSP[NH1+1]PSBr', 0.6103542361115243),\n",
       " ('BrSPPF', 0.6095399334272483),\n",
       " ('Br[C@@H1]C[N+1]C[C@@H1]S/C', 0.6083837766392202),\n",
       " ('ClP/CSBr', 0.6078379814215613),\n",
       " ('FOC[C@@H1]=C/C[C@H1]Br', 0.6061416779258509),\n",
       " ('[N+1][C@H1]SP=NBr', 0.6056447827520997),\n",
       " ('N[C@@H1][C@H1]O[C@H1]Br', 0.6050545358676085),\n",
       " ('Cl[C@H1]=C[NH2+1]OBr', 0.6048433593114577),\n",
       " ('CSPPBr', 0.6042888519367224),\n",
       " ('CSPPBr', 0.6042888519367224),\n",
       " ('BrS[C@@H1]S#N', 0.6041190735681806),\n",
       " ('CNS[C@H1]Br', 0.6040509881297893),\n",
       " ('OS[C@H1]=CSOC', 0.6035653187394786),\n",
       " ('OC[C@@H1]OBr', 0.6033747616596256),\n",
       " ('FS[C@H1]C[C@@H1]=C[C@H1][C@H1]O', 0.6025793819672379),\n",
       " ('CO[C@@H1]SBr', 0.6022394894421147),\n",
       " ('CO[C@H1]SBr', 0.6022394894421147),\n",
       " ('N[C@@H1][NH1][C@@H1]=CBr', 0.6016318651600017),\n",
       " ('N[C@@H1]S[C@@H1]=CCl', 0.6010304941670338),\n",
       " ('Br[C@H1]CCBr', 0.6009187688315859),\n",
       " ('[NH1]=C/CSBr', 0.6006861750768895),\n",
       " ('BrOPBr', 0.5996685333173501),\n",
       " ('BrOPBr', 0.5996685333173501),\n",
       " ('BrO[C@H1]S[C@@H1]', 0.5994982243903136),\n",
       " ('C[NH1][C@H1]=CSCl', 0.5983777390426599),\n",
       " ('O[C@@H1]SBr', 0.5983665451943212),\n",
       " ('BrO/CSCl', 0.5979690642249763),\n",
       " ('ClOCSBr', 0.5979690642249764),\n",
       " ('C/CS#C[C@H1]S[C@H1]=C[C@@H1][N+1]', 0.5974187658716617),\n",
       " ('BrS#CCP=NP', 0.5971815682052957),\n",
       " ('NPS[C@H1]=C(N)[N+1]P', 0.5968751915621955),\n",
       " ('C(S)[C@@H1]=C[C@H1]Br', 0.5958502797523243),\n",
       " ('Cl[C@@H1]/CNBr', 0.5957397957301491),\n",
       " ('NPS[C@H1]=CCl', 0.5947562543817696),\n",
       " ('N[C@@H1]=CSPCl', 0.5947562543817696),\n",
       " ('Br/C=C[NH1+1]Br', 0.5944189928237078),\n",
       " ('BrS[C@H1][C@H1]=CP', 0.5939603031446797),\n",
       " ('Br[C@@H1][C@@H1]CN', 0.593706515004251),\n",
       " ('C(O)[C@@H1]PBr', 0.593675579228262),\n",
       " ('Br[C@@H1](C)OBr', 0.5934198073743673),\n",
       " ('ClC[C@H1]S#COBr', 0.593344557276869),\n",
       " ('CC[C@@H1](C)NBr', 0.5932861518858187),\n",
       " ('NPC[C@@H1]Br', 0.5931368036051091),\n",
       " ('BrCSBr', 0.5930429662028799),\n",
       " ('BrCSBr', 0.5930429662028799),\n",
       " ('BrCSBr', 0.5930429662028799),\n",
       " ('BrS/CBr', 0.5930429662028799),\n",
       " ('C[NH1]P[C@@H1]Br', 0.5924316744165873)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(s,rdkit.Chem.QED.qed(rdkit.Chem.MolFromSmiles(s))) for s in selfies_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks =[(sf.decoder(dm._string_to_selfie(a)), dm._string_to_selfie(a)) for a in dm.actions[31:]]\n",
    "#chunks =[sf.decoder(dm._string_to_selfie(a)) for a in dm.actions[31:]]\n",
    "el = chunks[-3][1]\n",
    "\n",
    "\n",
    "one = sf.decoder(el)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SBr', 0.44841819337939126),\n",
       " ('BrS', 0.44841819337939126),\n",
       " ('[C@@H1]SBr', 0.47430278463097686),\n",
       " ('OBr', 0.4600586231697684),\n",
       " ('[C@H1]SBr', 0.47430278463097686),\n",
       " ('Br[C@@H1]', 0.41944927628282164),\n",
       " ('Br[C@H1]', 0.41944927628282164),\n",
       " ('BrO', 0.4600586231697684),\n",
       " ('BrO', 0.4600586231697684),\n",
       " ('Br[N+1]', 0.41325513140013265),\n",
       " ('BrN', 0.42962990575410526),\n",
       " ('BrS[C@@H1]SBr', 0.7226730225880351),\n",
       " ('BrN', 0.42962990575410526),\n",
       " ('BrS[C@H1]SBr', 0.7226730225880351),\n",
       " ('BrS[C@@H1]SBr', 0.7226730225880351),\n",
       " ('BrS[C@@H1]SBr', 0.7226730225880351),\n",
       " ('BrS[C@@H1]SBr', 0.7226730225880351),\n",
       " ('[C@@H1]=C', 0.36416909733079994),\n",
       " ('BrP', 0.4133081920445781)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(s,rdkit.Chem.QED.qed(rdkit.Chem.MolFromSmiles(s))) for s in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6473, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#logreward, state, actions, trajectories, dones = get_samples(4703145, 2024, \"no_chunk\", n_samples=2**14)\n",
    "#print(torch.topk(logreward, k=100).values.exp().median())\n",
    "#logreward, state, actions, trajectories, dones = get_samples(4703134, 1998, \"no_chunk\", n_samples=2**12)\n",
    "#print(torch.topk(logreward, k=100).values.exp().median())\n",
    "logreward, state, actions, trajectories, dones = get_samples(4703155, 42, \"no_chunk\", n_samples=2**14)\n",
    "print(torch.topk(logreward, k=100).values.exp().median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6341, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6349, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#logreward, state, actions, trajectories, dones = get_samples(4703142, 2024, \"chunk_replacement\", n_samples=2**14)\n",
    "#print(torch.topk(logreward, k=100).values.exp().median())\n",
    "logreward, state, actions, trajectories, dones = get_samples(4703134, 1998, \"chunk_replacement\", n_samples=2**14)\n",
    "print(torch.topk(logreward, k=100).values.exp().median())\n",
    "logreward, state, actions, trajectories, dones = get_samples(4703152, 42, \"chunk_replacement\", n_samples=2**14)\n",
    "print(torch.topk(logreward, k=100).values.exp().median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_scientist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
