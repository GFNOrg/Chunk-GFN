from itertools import cycle
from typing import ClassVar, Literal, Optional, Tuple, Union, cast

import torch
from gfn.actions import Actions
from gfn.env import DiscreteEnv
from gfn.preprocessors import IdentityPreprocessor
from gfn.states import DiscreteStates, States
from torch.utils.data import DataLoader, Dataset
from torchtyping import TensorType as TT


class ConditionalGeneration(DiscreteEnv):
    def __init__(
        self,
        dataset: Dataset,
        batch_size: int,
        max_len: int,
        vocab: set[str | int],
        device_str: Literal["cpu", "cuda"] = "cpu",
    ):
        """
        Args:
            dataloader: A dataloader that provides the conditioning sequences.
            batch_size: Batch size to be used for the dataloader
            max_len: The maximum length of a sequence, whether it comes from the dataloader or the one generated by the GFlowNet.
            vocab: The vocabulary used to generate the sequence. This will be used to get actions.
        """

        self.dataset = dataset
        self.max_len = max_len
        self.vocab = vocab
        self.batch_size = batch_size

        self.dataloader = DataLoader(dataset, batch_size=batch_size)
        self.dl_iterator = cycle(self.dataloader)

        n_actions = len(self.vocab) + 1
        self.ndim = len(vocab)

        s0 = torch.full(
            (2 * max_len, len(self.vocab)),
            -1,
            dtype=torch.long,
            device=torch.device(device_str),
        )
        sf = torch.full(
            (2 * max_len, len(self.vocab)),
            2,
            dtype=torch.long,
            device=torch.device(device_str),
        )

        preprocessor = IdentityPreprocessor(output_dim=self.ndim)

        super().__init__(
            n_actions=n_actions,
            s0=s0,
            sf=sf,
            device_str=device_str,
            preprocessor=preprocessor,
        )

    def reset(
        self,
        batch_shape: Optional[Union[int, Tuple[int]]] = None,
        random: bool = False,
        sink: bool = False,
        seed: int = None,
    ) -> States:
        """
        Instantiates a batch of initial states. random and sink cannot be both True.
        When random is true and seed is not None, environment randomization is fixed by
        the submitted seed for reproducibility.
        """
        # TODO: Remove this thing
        self.dl_iterator = cycle(self.dataloader)
        assert not (random and sink)

        if random and seed is not None:
            torch.manual_seed(seed)

        if batch_shape is None:
            batch_shape = (1,)
        if isinstance(batch_shape, int):
            batch_shape = (batch_shape,)
        # Sample from the dataloader and concatenate to the "initial" states
        return self.States.from_batch_shape(
            batch_shape=batch_shape, random=random, sink=sink
        )

    def make_States_class(self) -> type[DiscreteStates]:
        env = self

        class ConditionalGenerationStates(DiscreteStates):
            state_shape: ClassVar[tuple[int, ...]] = (
                2 * env.max_len,
                env.ndim,
            )
            s0 = env.s0
            sf = env.sf
            n_actions = env.n_actions
            device = env.device

            @classmethod
            def make_random_states_tensor(
                cls, batch_shape: Tuple[int, ...]
            ) -> TT["batch_shape", "state_shape", torch.float]:
                # TODO: remove this
                x = next(env.dl_iterator).to(env.device).long()
                s = -torch.ones_like(x).to(env.device).long()
                s = torch.cat([x, s], dim=1)
                return s

            def update_masks(self) -> None:
                # The following two lines are for typing only.
                self.forward_masks = cast(
                    TT["batch_shape", "n_actions", torch.bool],
                    self.forward_masks,
                )
                self.backward_masks = cast(
                    TT["batch_shape", "n_actions - 1", torch.bool],
                    self.backward_masks,
                )
                batch_ndim = len(self.batch_shape)
                index = [slice(None)] * batch_ndim + [2 * env.max_len - 1]
                # TODO: Mask exit actions
                self.forward_masks[..., :-1] = self.tensor[index] == -1
                index = [slice(None)] * batch_ndim + [env.max_len]
                self.backward_masks = self.tensor[index] != -1

            def compare(
                self, other: TT["batch_shape", "state_shape", torch.float]
            ) -> TT["batch_shape", torch.bool]:
                """Computes elementwise equality between state tensor with an external tensor.
                We only compare the second parts of the states.
                Args:
                    other: Tensor of states to compare to.

                Returns: Tensor of booleans indicating whether the states are equal to the
                    states in self.
                """
                batch_ndim = len(self.batch_shape)
                index = [slice(None)] * batch_ndim + [slice(env.max_len, None)]
                out = torch.ones_like(other, dtype=bool)
                out[index] = self.tensor[index] == other[index]
                state_ndim = len(self.__class__.state_shape)
                for _ in range(state_ndim):
                    out = out.all(dim=-1)
                return out

        return ConditionalGenerationStates

    def maskless_step(
        self, states: States, actions: Actions
    ) -> TT["batch_shape", "state_shape", torch.float]:
        # https://stackoverflow.com/questions/56088189/pytorch-how-can-i-find-indices-of-first-nonzero-element-in-each-row-of-a-2d-ten
        idx = torch.arange(2 * self.max_len, 0, -1).to(self.device)
        indices = torch.argmin(idx * states.tensor[..., 0], dim=1)
        indices = indices.reshape(-1, 1)
        act = torch.zeros(*actions.batch_shape, self.n_actions).to(self.device).long()
        act = act.scatter_(
            1,
            actions.tensor,
            torch.ones((*actions.batch_shape, 1)).long().to(self.device),
        )
        act = act[:, : self.n_actions - 1]
        states.tensor = states.tensor.scatter_(
            1, indices.unsqueeze(-1).repeat(1, 1, self.ndim), act.unsqueeze(1)
        )
        return states.tensor

    def maskless_backward_step(
        self, states: States, actions: Actions
    ) -> TT["batch_shape", "state_shape", torch.float]:
        idx = torch.arange(2 * self.max_len, 0, -1).to(self.device)
        indices = torch.argmin(idx * states.tensor[..., 0], dim=1)
        indices = indices.reshape(-1, 1)
        act = -torch.ones(*actions.batch_shape, self.ndim).to(self.device).long()
        states.tensor = states.tensor.scatter_(
            1, indices.unsqueeze(-1).repeat(1, 1, self.ndim), act.unsqueeze(1)
        )

    def log_reward(self, final_states: DiscreteStates) -> TT["batch_shape"]:
        raw_states = final_states.tensor.float()
        x = raw_states[:, : self.max_len]
        s = raw_states[:, self.max_len :]
        reward = -0.5 * ((x - s) ** 2).mean((1, 2))
        return reward
